{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbbgDn-0EdMv",
        "outputId": "ed0fc27b-ae07-4869-a3c7-8d59b3f3ad49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (2.160.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.19.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.66.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (4.25.6)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.26.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2025.1.31)\n",
            "Collecting comments for video: aZN_ZgR_j_8\n",
            "Collected 100 comments from video ID: aZN_ZgR_j_8\n",
            "Collecting comments for video: heUQx35qXio\n",
            "Collected 51 comments from video ID: heUQx35qXio\n",
            "Collecting comments for video: nBq60wwkg7k\n",
            "Collected 15 comments from video ID: nBq60wwkg7k\n",
            "Collecting comments for video: mQrZuW-ooUs\n",
            "Collected 5 comments from video ID: mQrZuW-ooUs\n",
            "Collecting comments for video: _WLs1E5tRUc\n",
            "Collected 4 comments from video ID: _WLs1E5tRUc\n",
            "Collecting comments for video: JdwCcU1njMA\n",
            "Collected 4 comments from video ID: JdwCcU1njMA\n",
            "Collecting comments for video: xBimuKlO_8Q\n",
            "Collected 3 comments from video ID: xBimuKlO_8Q\n",
            "Collecting comments for video: rwkstgOjQ5I\n",
            "Collected 3 comments from video ID: rwkstgOjQ5I\n",
            "Collecting comments for video: gobeJXbFtBk\n",
            "Collected 7 comments from video ID: gobeJXbFtBk\n",
            "Collecting comments for video: 33YwDyW31DE\n",
            "Collected 3 comments from video ID: 33YwDyW31DE\n",
            "Collecting comments for video: jVYAjmWo-C0\n",
            "Collected 8 comments from video ID: jVYAjmWo-C0\n",
            "Collecting comments for video: 1vzxMcXTwSI\n",
            "Collected 9 comments from video ID: 1vzxMcXTwSI\n",
            "Collecting comments for video: EI7TiCOKj-s\n",
            "Collected 153 comments from video ID: EI7TiCOKj-s\n",
            "Collecting comments for video: K0ZN233sp1c\n",
            "Collected 5 comments from video ID: K0ZN233sp1c\n",
            "Collecting comments for video: QA9QQCvbvyU\n",
            "Collected 4 comments from video ID: QA9QQCvbvyU\n",
            "Collecting comments for video: 0xXLw1Q9HF4\n",
            "Collected 36 comments from video ID: 0xXLw1Q9HF4\n",
            "Collecting comments for video: odNH2op25RM\n",
            "Collected 53 comments from video ID: odNH2op25RM\n",
            "Collecting comments for video: pDKNB8WA47I\n",
            "Collected 204 comments from video ID: pDKNB8WA47I\n",
            "Collecting comments for video: VOxVjF1kr-U\n",
            "Collected 129 comments from video ID: VOxVjF1kr-U\n",
            "Collecting comments for video: E3mSYrbqml4\n",
            "Collected 11 comments from video ID: E3mSYrbqml4\n",
            "Collecting comments for video: jilktmDiBvY\n",
            "Collected 1 comments from video ID: jilktmDiBvY\n",
            "Collecting comments for video: EV4J8J6RlOE\n",
            "Collected 353 comments from video ID: EV4J8J6RlOE\n",
            "Collecting comments for video: 0SDrhZ-jBSw\n",
            "Collected 319 comments from video ID: 0SDrhZ-jBSw\n",
            "Collecting comments for video: XYZNdcQUKWU\n",
            "Collected 34 comments from video ID: XYZNdcQUKWU\n",
            "Collecting comments for video: 4ZdQyk7Pq_s\n",
            "Collected 404 comments from video ID: 4ZdQyk7Pq_s\n",
            "Collecting comments for video: Cxi9npzQqbQ\n",
            "Collected 28 comments from video ID: Cxi9npzQqbQ\n",
            "Collecting comments for video: NJbZICrq_9A\n",
            "Collected 61 comments from video ID: NJbZICrq_9A\n",
            "Collecting comments for video: 63dhJUDsI6U\n",
            "Collected 56 comments from video ID: 63dhJUDsI6U\n",
            "Collecting comments for video: 55tJji52K8k\n",
            "Collected 738 comments from video ID: 55tJji52K8k\n",
            "Collecting comments for video: ulT6T8KKRI0\n",
            "Collected 13 comments from video ID: ulT6T8KKRI0\n",
            "Collecting comments for video: KdtrPVgkfas\n",
            "Collected 9 comments from video ID: KdtrPVgkfas\n",
            "Collecting comments for video: YCkahuYfynU\n",
            "Collected 5 comments from video ID: YCkahuYfynU\n",
            "Collecting comments for video: tqMaLCwYuiw\n",
            "Collected 37 comments from video ID: tqMaLCwYuiw\n",
            "Collecting comments for video: e6HIRBwLGeM\n",
            "Collected 23 comments from video ID: e6HIRBwLGeM\n",
            "Collecting comments for video: EHe-YpY0WG0\n",
            "Collected 4 comments from video ID: EHe-YpY0WG0\n",
            "Collecting comments for video: 0PLHVzteHRY\n",
            "Collected 144 comments from video ID: 0PLHVzteHRY\n",
            "Collecting comments for video: IBLgV3gdwtA\n",
            "Collected 95 comments from video ID: IBLgV3gdwtA\n",
            "Collecting comments for video: 15C8mfeY290\n",
            "Collected 117 comments from video ID: 15C8mfeY290\n",
            "Collecting comments for video: N6nGRCUWkIM\n",
            "Collected 44 comments from video ID: N6nGRCUWkIM\n",
            "Collecting comments for video: rgxmIqZ4fMw\n",
            "Collected 26 comments from video ID: rgxmIqZ4fMw\n",
            "Collecting comments for video: bvWe5_EvteM\n",
            "Collected 488 comments from video ID: bvWe5_EvteM\n",
            "Collecting comments for video: NX6iHRYFZaw\n",
            "Collected 183 comments from video ID: NX6iHRYFZaw\n",
            "Collecting comments for video: -LhS8D4nqng\n",
            "Collected 770 comments from video ID: -LhS8D4nqng\n",
            "Collecting comments for video: qRb_72NgFLo\n",
            "Collected 48 comments from video ID: qRb_72NgFLo\n",
            "Collecting comments for video: 94HekzWPmCc\n",
            "Collected 31 comments from video ID: 94HekzWPmCc\n",
            "Collecting comments for video: pdU9kzI-7Hg\n",
            "Collected 213 comments from video ID: pdU9kzI-7Hg\n",
            "Collecting comments for video: 2ET4VgCpJ2k\n",
            "Collected 1381 comments from video ID: 2ET4VgCpJ2k\n",
            "Collecting comments for video: 0VVkPxN_C0Y\n",
            "Collected 52 comments from video ID: 0VVkPxN_C0Y\n",
            "Collecting comments for video: ZrW3oFRqkdg\n",
            "Collected 74 comments from video ID: ZrW3oFRqkdg\n",
            "Collecting comments for video: A6yZVDJ6rIY\n",
            "Collected 18 comments from video ID: A6yZVDJ6rIY\n",
            "Collecting comments for video: vMirkVh4I-w\n",
            "Collected 497 comments from video ID: vMirkVh4I-w\n",
            "Collecting comments for video: 4-tLhqZZC6A\n",
            "Collected 16 comments from video ID: 4-tLhqZZC6A\n",
            "Collecting comments for video: H89jbSTH2p8\n",
            "Collected 34 comments from video ID: H89jbSTH2p8\n",
            "Collecting comments for video: 2QW34US0QrA\n",
            "Collected 259 comments from video ID: 2QW34US0QrA\n",
            "Collecting comments for video: J-bfaC8baeg\n",
            "Collected 24 comments from video ID: J-bfaC8baeg\n",
            "Collecting comments for video: 912mc32Ej9g\n",
            "Collected 165 comments from video ID: 912mc32Ej9g\n",
            "Collecting comments for video: 8a7eUHR73To\n",
            "Collected 14 comments from video ID: 8a7eUHR73To\n",
            "Collecting comments for video: tQfrzYUiong\n",
            "Collected 8 comments from video ID: tQfrzYUiong\n",
            "Collecting comments for video: p6XKfa9IpR4\n",
            "Collected 58 comments from video ID: p6XKfa9IpR4\n",
            "Collecting comments for video: jG8xm3Uuoa0\n",
            "Collected 17 comments from video ID: jG8xm3Uuoa0\n",
            "Collecting comments for video: BZvxmonSf4c\n",
            "Collected 48 comments from video ID: BZvxmonSf4c\n",
            "Collecting comments for video: QIWX4oNn3Y0\n",
            "Collected 6 comments from video ID: QIWX4oNn3Y0\n",
            "Collecting comments for video: Q3a2bZkWAIY\n",
            "Collected 116 comments from video ID: Q3a2bZkWAIY\n",
            "Collecting comments for video: LV7im5BBMYQ\n",
            "Collected 16 comments from video ID: LV7im5BBMYQ\n",
            "Collecting comments for video: SobAzfneQU0\n",
            "Collected 229 comments from video ID: SobAzfneQU0\n",
            "Collecting comments for video: riKowdciniU\n",
            "Collected 145 comments from video ID: riKowdciniU\n",
            "Collecting comments for video: 72WgjWOLOH4\n",
            "Collected 22 comments from video ID: 72WgjWOLOH4\n",
            "Collecting comments for video: r0o64vcdl3g\n",
            "Collected 211 comments from video ID: r0o64vcdl3g\n",
            "Collecting comments for video: kXc9L-agT9Q\n",
            "Collected 42 comments from video ID: kXc9L-agT9Q\n",
            "Collecting comments for video: vUuzMYbdxAo\n",
            "Collected 15 comments from video ID: vUuzMYbdxAo\n",
            "Collecting comments for video: -C9K4f5ss3M\n",
            "Collected 38 comments from video ID: -C9K4f5ss3M\n",
            "Collecting comments for video: x7JiIoI5tfg\n",
            "Collected 370 comments from video ID: x7JiIoI5tfg\n",
            "Collecting comments for video: tRkIaCSXjo0\n",
            "Collected 416 comments from video ID: tRkIaCSXjo0\n",
            "Collecting comments for video: clr4vID8eVY\n",
            "Collected 11 comments from video ID: clr4vID8eVY\n",
            "Collecting comments for video: -7wGu2GxMSw\n",
            "Collected 110 comments from video ID: -7wGu2GxMSw\n",
            "Collecting comments for video: R8U-DJSNEUY\n",
            "Collected 120 comments from video ID: R8U-DJSNEUY\n",
            "Collecting comments for video: pbSG3zLuvuU\n",
            "Collected 211 comments from video ID: pbSG3zLuvuU\n",
            "Collecting comments for video: rzYt9pSSZLc\n",
            "Collected 146 comments from video ID: rzYt9pSSZLc\n",
            "Collecting comments for video: lv5GMUAZOBM\n",
            "Collected 218 comments from video ID: lv5GMUAZOBM\n",
            "Collecting comments for video: pqbyeO8yj4g\n",
            "Collected 201 comments from video ID: pqbyeO8yj4g\n",
            "Collecting comments for video: 2xtw_arzhoI\n",
            "Collected 512 comments from video ID: 2xtw_arzhoI\n",
            "Collecting comments for video: P5W_OuKnvBQ\n",
            "Collected 1189 comments from video ID: P5W_OuKnvBQ\n",
            "Collecting comments for video: yVm4vEe_vlE\n",
            "Collected 134 comments from video ID: yVm4vEe_vlE\n",
            "Number of comments: 12194\n",
            "Saved 12194 comments to doublej_music_comments.csv\n"
          ]
        }
      ],
      "source": [
        "# Install required library\n",
        "!pip install google-api-python-client pandas\n",
        "\n",
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Set up YouTube API credentials\n",
        "API_KEY = \"API\"  # Replace with your API key\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
        "\n",
        "\n",
        "# Function to clean comments\n",
        "def clean_comment(comment):\n",
        "    \"\"\"\n",
        "    Clean a comment by removing HTML tags and unnecessary whitespace.\n",
        "    \"\"\"\n",
        "    comment = re.sub(r'<[^>]+>', '', comment).strip()  # Remove HTML tags and trim\n",
        "    return comment if comment else None  # Return None if the comment is empty\n",
        "\n",
        "# Function to get comments from a YouTube video\n",
        "def get_video_comments(video_id):\n",
        "    comments = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        request = youtube.commentThreads().list(\n",
        "            part=\"snippet\",\n",
        "            videoId=video_id,\n",
        "            pageToken=next_page_token,\n",
        "            maxResults=100\n",
        "        )\n",
        "        response = request.execute()\n",
        "\n",
        "        for item in response.get(\"items\", []):\n",
        "            # Extract and clean the comment\n",
        "            raw_comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
        "            cleaned_comment = clean_comment(raw_comment)\n",
        "            if cleaned_comment:  # Include only cleaned, non-empty comments\n",
        "                comments.append(cleaned_comment)\n",
        "\n",
        "        next_page_token = response.get(\"nextPageToken\", None)\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    print(f\"Collected {len(comments)} comments from video ID: {video_id}\")\n",
        "    return comments\n",
        "\n",
        "# Save comments to a CSV file (without IDs)\n",
        "def save_comments_to_csv(video_ids, output_file):\n",
        "    all_comments = []\n",
        "\n",
        "    for video_id in video_ids:\n",
        "        print(f\"Collecting comments for video: {video_id}\")\n",
        "        comments = get_video_comments(video_id)\n",
        "\n",
        "        all_comments.extend(comments)\n",
        "\n",
        "    # Debugging: Ensure there are comments collected\n",
        "    print(\"Number of comments:\", len(all_comments))\n",
        "\n",
        "    # Save comments to a CSV file\n",
        "    df = pd.DataFrame({\"comment\": all_comments})\n",
        "    df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
        "\n",
        "    print(f\"Saved {len(all_comments)} comments to {output_file}\")\n",
        "\n",
        "\n",
        "# Example usage\n",
        "video_ids = [\"aZN_ZgR_j_8\", \"heUQx35qXio\", \"nBq60wwkg7k\", \"mQrZuW-ooUs\", \"_WLs1E5tRUc\", \"JdwCcU1njMA\", \"xBimuKlO_8Q\", \"rwkstgOjQ5I\", \"gobeJXbFtBk\", \"33YwDyW31DE\",\n",
        "             \"jVYAjmWo-C0\", \"1vzxMcXTwSI\", \"EI7TiCOKj-s\", \"K0ZN233sp1c\", \"QA9QQCvbvyU\", \"0xXLw1Q9HF4\", \"odNH2op25RM\", \"pDKNB8WA47I\", \"VOxVjF1kr-U\", \"E3mSYrbqml4\",\n",
        "             \"jilktmDiBvY\", \"EV4J8J6RlOE\", \"0SDrhZ-jBSw\", \"XYZNdcQUKWU\", \"4ZdQyk7Pq_s\", \"Cxi9npzQqbQ\", \"NJbZICrq_9A\", \"63dhJUDsI6U\", \"55tJji52K8k\", \"ulT6T8KKRI0\",\n",
        "             \"KdtrPVgkfas\", \"YCkahuYfynU\", \"tqMaLCwYuiw\", \"e6HIRBwLGeM\", \"EHe-YpY0WG0\", \"0PLHVzteHRY\", \"IBLgV3gdwtA\", \"15C8mfeY290\", \"N6nGRCUWkIM\", \"rgxmIqZ4fMw\",\n",
        "             \"bvWe5_EvteM\", \"NX6iHRYFZaw\", \"-LhS8D4nqng\", \"qRb_72NgFLo\", \"94HekzWPmCc\", \"pdU9kzI-7Hg\", \"2ET4VgCpJ2k\", \"0VVkPxN_C0Y\", \"ZrW3oFRqkdg\", \"A6yZVDJ6rIY\",\n",
        "             \"vMirkVh4I-w\", \"4-tLhqZZC6A\", \"H89jbSTH2p8\", \"2QW34US0QrA\", \"J-bfaC8baeg\", \"912mc32Ej9g\", \"8a7eUHR73To\", \"tQfrzYUiong\", \"p6XKfa9IpR4\", \"jG8xm3Uuoa0\",\n",
        "             \"BZvxmonSf4c\", \"QIWX4oNn3Y0\", \"Q3a2bZkWAIY\", \"LV7im5BBMYQ\", \"SobAzfneQU0\", \"riKowdciniU\", \"72WgjWOLOH4\", \"r0o64vcdl3g\", \"kXc9L-agT9Q\", \"vUuzMYbdxAo\",\n",
        "             \"-C9K4f5ss3M\", \"x7JiIoI5tfg\", \"tRkIaCSXjo0\", \"clr4vID8eVY\", \"-7wGu2GxMSw\", \"R8U-DJSNEUY\", \"pbSG3zLuvuU\", \"rzYt9pSSZLc\", \"lv5GMUAZOBM\", \"pqbyeO8yj4g\",\n",
        "             \"2xtw_arzhoI\", \"P5W_OuKnvBQ\", \"yVm4vEe_vlE\"]  # Replace with YouTube video IDs\n",
        "save_comments_to_csv(video_ids, \"doublej_music_comments.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CBGjTMTVBX8",
        "outputId": "8bb57b22-c937-42da-a62b-0d72c85fb405"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved 8632 filtered comments with IDs to doublej_filtered_comments_with_id.csv\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Function to clean comments (keeping only Burmese and emojis)\n",
        "def clean_burmese_comments(comment):\n",
        "    \"\"\"\n",
        "    Clean a comment by keeping only Burmese characters and emojis.\n",
        "    Removes English, Japanese, Chinese, or any other non-Burmese text.\n",
        "    \"\"\"\n",
        "    # Regex pattern for Burmese characters (including mixed Burmese text) and emojis\n",
        "    burmese_pattern = re.compile(r'[\\u1000-\\u109F\\s\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F]')\n",
        "\n",
        "    # Find all Burmese characters and emojis\n",
        "    cleaned_comment = \"\".join(re.findall(burmese_pattern, comment))\n",
        "\n",
        "    # Return None if the comment becomes empty after cleaning\n",
        "    return cleaned_comment.strip() if cleaned_comment.strip() else None\n",
        "\n",
        "# Load the CSV file with saved comments\n",
        "def load_comments_from_csv(input_file):\n",
        "    df = pd.read_csv(input_file)\n",
        "    return df['comment'].tolist()  # Assuming the column is named 'comment'\n",
        "\n",
        "# Filter the comments to keep only Burmese and emojis\n",
        "def filter_burmese_comments(comments):\n",
        "    # Clean and filter out None, empty, or whitespace-only comments\n",
        "    return [clean_burmese_comments(comment) for comment in comments if clean_burmese_comments(comment)]\n",
        "\n",
        "# Save filtered comments to a new CSV file (with ID column)\n",
        "def save_filtered_comments_to_csv(filtered_comments, output_file):\n",
        "    # Ensure only valid (non-empty) comments are included\n",
        "    if len(filtered_comments) == 0:\n",
        "        print(\"No valid comments to save.\")\n",
        "        return\n",
        "\n",
        "    # Generate IDs for the filtered comments\n",
        "    comment_ids = list(range(1, len(filtered_comments) + 1))  # Generating IDs\n",
        "\n",
        "    # Create the DataFrame with valid comments and IDs\n",
        "    df = pd.DataFrame({\"ID\": comment_ids, \"comment\": filtered_comments})\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
        "    print(f\"Saved {len(filtered_comments)} filtered comments with IDs to {output_file}\")\n",
        "\n",
        "# Main processing function\n",
        "def process_comments(input_file, output_file):\n",
        "    # Load comments from the CSV\n",
        "    comments = load_comments_from_csv(input_file)\n",
        "\n",
        "    # Filter comments (only Burmese and emojis)\n",
        "    filtered_comments = filter_burmese_comments(comments)\n",
        "\n",
        "    # Save filtered comments to new CSV with IDs\n",
        "    save_filtered_comments_to_csv(filtered_comments, output_file)\n",
        "\n",
        "# Example usage\n",
        "input_file = \"doublej_music_comments.csv\"  # Replace with your file path\n",
        "output_file = \"doublej_filtered_comments_with_id.csv\"  # Output file path\n",
        "process_comments(input_file, output_file)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
